\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{mathtools}
\usepackage{mdframed}
\usepackage{cancel}
\usepackage{import, xifthen, pdfpages, transparent}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{float}
\usepackage{tikz, pgfplots}
\usetikzlibrary{positioning}
\pgfplotsset{compat=1.18}
\geometry{a4paper, margin=2cm}

\newmdenv[
  linecolor=black,
  linewidth=1pt,
  roundcorner=5pt,
  innertopmargin=4pt,
  innerbottommargin=10pt,
  innerleftmargin=10pt,
  innerrightmargin=10pt
]{bxthm}

\theoremstyle{plain}
\newtheorem{thm}{Teorema}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione}
\newtheorem{cor}{Corollario}

\theoremstyle{definition}
\newtheorem{defn}{Definizione}[section]
\newtheorem{exmp}{Esempio}[section]
\newtheorem{xca}[exmp]{Esercizio}

\theoremstyle{remark}
\newtheorem{rem}{Osservazione}
\newtheorem{note}{Nota}
\newtheorem{case}{Caso}

\newcommand{\incfig}[2][\columnwidth]{%
    \def\svgwidth{#1}
    \import{./figures/}{#2.pdf_tex}
}

\begin{document}

\begin{titlepage}
    \centering
    {\scshape\LARGE Università degli Studi della Basilicata \par}
    \vspace{0.5cm}
    {\scshape\Large Dipartimento di Matematica, Informatica ed Economia \par} 
    
    \vspace{2.5cm}

    % Linea orizzontale superiore
    \rule{\linewidth}{0.5mm}
    \vspace{0.4cm}
    
    {\huge\bfseries Calcolo Scientifico \par}
    \vspace{0.2cm}
    {\Large\itshape Appunti delle lezioni ed esercizi rielaborati \par}
    
    \vspace{0.4cm}
    % Linea orizzontale inferiore
    \rule{\linewidth}{0.5mm}
    
    \vspace{3cm}

    % Blocco Studente e Docente
    \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \large
            \emph{Studente:}\\
            \textbf{Donato Martinelli}\\
            Matr. 69060 
        \end{flushleft}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \begin{flushright} \large
            \emph{Docente:}\\
            Prof.ssa \textbf{Carmela De Bonis}
        \end{flushright}
    \end{minipage}

    \vfill

    {\large Anno Accademico 2025/2026 \par}

\end{titlepage}

\tableofcontents

\newpage
Questo documento rappresenta un riassunto concettuale del materiale trattato. 
Non tutti gli esempi e i dettagli sono stati riportati. 
Si consiglia di studiare la teoria approfonditamente e di verificare, per ciascun argomento, 
la presenza di esercizi o esempi pratici nelle slide corrispondenti, da analizzare eventualmente 
con l'ausilio di Matlab.

\newpage

\section{Introduzione}

\paragraph{Il Ruolo della Matematica e la Modellizzazione}
La matematica è uno strumento indispensabile per l'interpretazione e la predizione dei fenomeni reali, ponendosi alla base di tutte le scienze. 
Gli scienziati cercano di ricavare un modello matematico (variabili, parametri, relazioni) che sia rigoroso e coerente con il fenomeno.
La complessità del fenomeno determina la quantità di dati necessari e il numero di variabili del modello. Le proprietà incognite si deducono risolvendo tale modello.

\paragraph{Necessità dell'Approccio Numerico}
Spesso la soluzione non è disponibile in forma esplicita o non è calcolabile analiticamente, rendendo necessario un metodo numerico di approssimazione. 
Anche quando la risoluzione analitica è possibile, essa può risultare troppo onerosa computazionalmente all'aumentare delle dimensioni del problema.

\paragraph{Esempi Introduttivi}
Per chiarire la necessità dell'approssimazione, consideriamo alcuni esempi:
\begin{itemize}
    \item \textbf{Equazione di secondo grado:} Data l'equazione $ax^{2}+bx+c=0$, le soluzioni sono $x_{1,2}=\frac{-b\pm\sqrt{b^{2}-4ac}}{2a}$.
    Se $a=1, b=1, c=-1$, le soluzioni sono $\frac{-1\pm\sqrt{5}}{2}$. Per individuare il valore numerico è necessario approssimare $\sqrt{5}$.
    \item \textbf{Equazione esponenziale:} La soluzione di $2^{x}=100$ è $x=\log_{2}(100)$. Anche qui, la risposta numerica richiede un'approssimazione.
    \item \textbf{Equazione trascendente:} L'equazione $2^{x}+x^{2}-3=0$ non è risolvibile analiticamente (non esplicitabile rispetto a $x$). 
    Sebbene studiabile graficamente, il calcolo delle soluzioni richiede obbligatoriamente un metodo numerico.
\end{itemize}

\paragraph{Definizione di Metodo Numerico}
Un metodo numerico è un processo implementabile su un calcolatore che fornisce una soluzione numerica in un numero finito di passi. 
Esistono metodi matematicamente validi che però non sono implementabili in un calcolatore per via dei tempi di esecuzione.

\paragraph{Caso Studio: Sistemi Lineari (Cramer vs Gauss)}
Un esempio cruciale riguarda la risoluzione di sistemi lineari, problema centrale nella modellistica.
\begin{itemize}
    \item \textbf{Il Metodo di Cramer (Non implementabile):} Se volessimo risolvere un sistema $20 \times 20$ ($n=20$) con Cramer, dovremmo calcolare 21 determinanti di ordine 20. 
    Con la regola di Laplace, le operazioni sono circa $21 \cdot 20! \approx 5.2 \cdot 10^{19}$. Su un processore da 3GHz ($3 \cdot 10^{9}$ op/sec), il tempo richiesto sarebbe superiore a 5 secoli. 
    È una procedura con tempo di esecuzione proibitivo.
    \item \textbf{Il Metodo di Eliminazione di Gauss (Efficiente):} Questo metodo richiede circa $\frac{n^{3}}{3}$ operazioni.
    Per $n=20$, servono solo 2667 operazioni ($0.88 \cdot 10^{-6}$ secondi).
    Per $n=1000$, servono 334 milioni di operazioni, eseguibili in un decimo di secondo.
\end{itemize}

\paragraph{Criteri di Scelta ed Errori}
La scelta del metodo si basa su due criteri fondamentali:
\begin{enumerate}
    \item \textbf{Efficienza:} minor numero di operazioni richieste.
    \item \textbf{Efficacia:} maggiore precisione di calcolo.
\end{enumerate}
Nonostante la potenza dei calcolatori moderni, i matematici affrontano ancora difficoltà. Poiché i numeri sono rappresentati in binario su una memoria finita, ogni memorizzazione introduce un errore .

\paragraph{Propagazione dell'Errore}
Un tema centrale del Calcolo Scientifico è la consapevolezza dell'errore e della sua propagazione. Alcuni metodi propagano gli errori (introdotti nei dati iniziali) al punto da fornire soluzioni completamente sbagliate. 
Si studia quindi la stabilità degli algoritmi rispetto a questi errori.

\vspace{20pt}

\section{Rappresentazione dei Numeri in un Calcolatore}
\subsection{Rappresentazione dei Numeri in un Calcolatore}
\paragraph{Sistemi di Numerazione e Cenni Storici}
Il numero è un concetto astratto, indipendente dai simboli usati per rappresentarlo. Un sistema di numerazione è uno schema che associa simboli ai numeri e definisce le regole per le operazioni.
Storicamente, i sistemi si sono evoluti da quelli \textit{additivi} (es. barrette verticali, numeri romani, egizi), dove il valore è la somma dei simboli e non serve lo zero, a quelli \textit{posizionali}, 
introdotti da indiani e arabi. In un sistema posizionale, il valore di una cifra dipende dalla posizione che occupa nella stringa numerica.

\paragraph{Il Sistema Decimale}
Il sistema decimale è posizionale, in base 10, e utilizza le cifre da 0 a 9. Ogni numero reale può essere rappresentato univocamente (eccetto casi di periodicità del 9) come somma di potenze di 10:
$$ z = \sum_{i=-M}^{m} a_i 10^i = \pm a_m 10^m + \dots + a_0 10^0 + a_{-1} 10^{-1} + \dots $$
dove $0 \le a_i \le 9$.

\paragraph{Il Sistema in Base N}
Generalizzando, qualunque intero $N > 1$ può essere scelto come base. Un numero reale $a$ si rappresenta come:
$$ a = \pm \sum_{i=-M}^{m} a_i N^i = \pm (a_m N^m + \dots + a_0 N^0 + a_{-1} N^{-1} + \dots) $$
dove i coefficienti soddisfano $0 \le a_i \le N-1$.
Anche in questo caso, la rappresentazione è unica eccetto quando la parte frazionaria contiene una sequenza infinita della cifra massima ammissibile ($N-1$). È importante notare che più piccola è la base $N$ scelta, più lunga sarà la stringa di caratteri necessaria per rappresentare lo stesso valore numerico.

\paragraph{Il Sistema Binario}
Nel calcolatore si utilizza il sistema binario (base $N=2$), poiché fisicamente realizzabile con oggetti che assumono due stati (es. magnetizzazione, conduttività). 
Le cifre 0 e 1 sono dette \textit{bit}. Un numero è rappresentato come:
$$ a = \pm \sum a_i 2^i \quad \text{con } 0 \le a_i \le 1 $$
Poiché la memoria è finita, i numeri vengono memorizzati in "parole" di lunghezza fissa $l$. Questo implica che solo un sottoinsieme di numeri reali, detti \textit{numeri macchina}, è rappresentabile esattamente.

\paragraph{Rappresentazione dei Numeri Interi}
Con parole di lunghezza $l$, si possono rappresentare gli interi nell'intervallo $[-\frac{2^l}{2}, \frac{2^l}{2}-1]$. Ad esempio, con $l=16$, l'intervallo è $[-32768, 32767]$.

\paragraph{Rappresentazione in Virgola Mobile (Floating-Point)}
Ogni numero reale $a$ può essere scritto come $a = p N^q$, dove $p$ è la \textit{mantissa} e $q$ l'\textit{esponente}. La rappresentazione si dice \textit{normalizzata} se:
$$ N^{-1} \le |p| < 1 $$
La normalizzazione riduce l'errore di rappresentazione e ottimizza la memoria.

\paragraph{Standard IEEE 754}
I calcolatori moderni seguono lo standard IEEE 754 per la rappresentazione in virgola mobile.
\begin{itemize}
    \item \textbf{Singola Precisione (32 bit):} 1 bit segno, 8 esponente, 23 mantissa. Permette circa 6 cifre significative e un esponente $q \in [-38, 38]$.
    \item \textbf{Doppia Precisione (64 bit):} 1 bit segno, 11 esponente, 52 mantissa. Grazie alla tecnica del "bit nascosto" (il primo bit è sempre 1 e non si memorizza), la mantissa effettiva è di 53 bit. Questo garantisce circa 16 cifre significative e $q \in [-308, 308]$.
\end{itemize}

\paragraph{Limiti e Numeri Speciali}
Dato un numero reale $a$, possono verificarsi diverse situazioni rispetto al range $[-308, 308]$ dell'esponente $q$:
\begin{itemize}
    \item \textbf{Overflow:} Se $q > 308$, il numero è troppo grande e viene indicato come Inf.
    \item \textbf{Underflow:} Se $q < -308$, si va sotto la soglia di precisione standard.
    \item \textbf{Numeri Denormalizzati:} I processori moderni gestiscono esponenti tra $-324$ e $-308$ riempiendo l'intervallo tra lo 0 e il più piccolo numero normalizzato ($realmin \approx 2.22 \cdot 10^{-308}$). 
    Sotto la soglia di $10^{-324}$ il valore diventa 0.
\end{itemize}

\paragraph{Approssimazione: Troncamento e Arrotondamento}
Se un numero ha più cifre significative di quelle rappresentabili (es. $>16$ in doppia precisione), deve essere approssimato a $t$ cifre.
\begin{itemize}
    \item \textbf{Troncamento ($trn(a)$):} Si eliminano semplicemente le cifre oltre la $t$-esima.
    \item \textbf{Arrotondamento ($arr(a)$):} Se la cifra $d_{t+1} \ge 5$, si incrementa la cifra $d_t$ di 1; altrimenti si tronca. Esempio con $\pi$ a 4 cifre: $trn(\pi)=0.3141 \cdot 10^1$, $arr(\pi)=0.3142 \cdot 10^1$.
\end{itemize}

\paragraph{Conseguenze della Aritmetica Finita}
L'insieme dei numeri macchina $F$ ha due limitazioni fondamentali rispetto ai reali $\mathbb{R}$:
1. \textbf{Limitatezza:} $F$ è limitato superiormente e inferiormente.
2. \textbf{Discretizzazione ("Bucato"):} $F$ non è denso. Tra due numeri macchina consecutivi non esistono altri numeri macchina rappresentabili, creando dei "buchi" di precisione.

\paragraph{Introduzione a MatLab}
MatLab (Matrix Laboratory) è un ambiente di calcolo basato sulle matrici. Tutte le variabili sono trattate internamente in \textit{doppia precisione} (16 cifre significative).
La visualizzazione dei risultati può essere modificata con il comando `format`:
\begin{itemize}
    \item `format short`: 5 cifre (default).
    \item `format long`: 16 cifre (virgola fissa).
    \item `format long e`: 16 cifre in notazione esponenziale (consigliato per l'analisi numerica).
\end{itemize}
Esempi pratici mostrano come MatLab gestisca i limiti della macchina:
\begin{itemize}
    \item Calcolo di $2^{-1074}$ restituisce un numero denormalizzato ($\approx 4.94 \cdot 10^{-324}$), mentre $2^{-1075}$ restituisce 0.
    \item Calcolo di $2^{1024}$ restituisce `Inf` (Overflow).
\end{itemize}

\subsection{Errori}
\paragraph{Sorgenti di Errore nel Calcolo Scientifico}
Risolvendo un problema matematico al calcolatore, le fonti di errore si dividono in due gruppi principali:
\begin{itemize}
    \item \textbf{Errori di rappresentazione (o arrotondamento):} Derivano dalla necessità di memorizzare numeri reali in uno spazio finito. Se la mantissa di un numero richiede più cifre di quelle disponibili ($t$), il numero viene troncato o arrotondato.
    \item \textbf{Errori nei calcoli (propagazione):} Operando su dati già approssimati (numeri macchina), l'errore iniziale si propaga nei risultati. L'entità di questa propagazione dipende dall'algoritmo utilizzato.
\end{itemize}

\paragraph{Definizioni di Errore}
Dato un numero reale esatto $a$ e la sua approssimazione $A$ (dove spesso $A = fl(a)$), si definiscono:
\begin{itemize}
    \item \textbf{Errore Assoluto:} $\Delta a = |a - A|$.
    \item \textbf{Errore Relativo:} $\delta a = \frac{|a - A|}{|a|}$. Questo errore rapporta l'imprecisione alla grandezza del numero, fornendo una misura più significativa della "bontà" dell'approssimazione.
\end{itemize}

\paragraph{Relazione tra Errori e Cifre Corrette}
Esistono legami precisi tra l'entità dell'errore e il numero di cifre corrette dell'approssimazione in base $N$:
\begin{itemize}
    \item \textbf{Cifre Decimali Corrette ($t$):} Se $\Delta a \le \frac{1}{2}N^{-t}$, allora $A$ ha almeno $t$ cifre decimali corrette.
    \item \textbf{Cifre Significative Corrette ($t$):} Se $\delta a \le \frac{1}{2}N^{-t+1}$, allora $A$ ha almeno $t$ cifre significative corrette.
\end{itemize}
La relazione per le cifre significative deriva dal fatto che, normalizzando, l'errore relativo dipende dall'errore sulla mantissa pesato per la base.

\paragraph{Esempi Numerici e Confronti}
L'analisi dei seguenti casi evidenzia come gli errori si comportano diversamente:
\begin{itemize}
    \item \textit{Caso 1:} $a=15.2000$, $A=15.1997$.
    Qui $\Delta a \approx 0.3 \cdot 10^{-3}$ e $\delta a \approx 0.19 \cdot 10^{-4}$. Il numero ha 3 cifre decimali e 5 cifre significative corrette.
    \item \textit{Caso 2 (Confronto):} $a=199.2000$, $A=199.1997$.
    L'errore assoluto è identico al Caso 1 ($\approx 0.3 \cdot 10^{-3}$), ma essendo $a$ più grande, l'errore relativo diminuisce ($\delta a \approx 0.15 \cdot 10^{-5}$). Risultato: 3 cifre decimali corrette ma ben 6 cifre significative corrette.
    \item \textit{Caso 3 (Anomalia visiva):} $a=1$, $A=0.9999$.
    Nonostante visivamente nessuna cifra coincida, si ha $\Delta a = 10^{-4}$ e $\delta a < \frac{1}{2}10^{-3}$. Matematicamente, $A$ ha 4 cifre decimali e 4 cifre significative corrette.
\end{itemize}

\paragraph{Unità di Roundoff ($u$)}
L'unità di roundoff $u$ è una costante che definisce la massima precisione di una specifica aritmetica floating-point. È definita dalla relazione:
$$ \frac{|fl(a) - a|}{|a|} \le u \quad \text{con} \quad u = \frac{1}{2}N^{1-t} $$
Questo implica che ogni numero macchina $fl(a)$ può essere scritto come $a(1+\delta)$ con $|\delta| \le u$. In pratica, l'errore relativo di rappresentazione non eccede mai $u$.

\paragraph{Precisione di Macchina ($\epsilon$)}
L'epsilon di macchina ($\epsilon$) è definita come la distanza tra 1 e il numero macchina successivo più grande. Esiste una relazione fondamentale tra $\epsilon$ e $u$:
$$ \epsilon = 2u $$
Per lo standard IEEE 754 in doppia precisione ($N=2$, $t=53$ bit di mantissa effettiva):
\begin{itemize}
    \item Unità di roundoff: $u = 2^{-53} \approx 1.11 \cdot 10^{-16}$.
    \item Epsilon macchina: $\epsilon = 2^{-52} \approx 2.22 \cdot 10^{-16}$.
\end{itemize}

\paragraph{Verifiche in Ambiente MatLab}
MatLab opera in doppia precisione. Alcuni esperimenti numerici mostrano i limiti della macchina:
\begin{itemize}
    \item \textbf{Test di granularità:} Il comando \texttt{1+eps > 1} restituisce \textit{Vero} (1), confermando che la macchina distingue i due valori. Invece, \texttt{1+eps/2 > 1} restituisce \textit{Falso} (0), poiché la variazione è inferiore alla sensibilità della macchina.
    \item \textbf{Epsilon relativo:} La funzione \texttt{eps(x)} restituisce la distanza tra $x$ e il numero macchina successivo. Tale distanza non è costante ma cresce con $x$. Vale l'uguaglianza \texttt{eps(1) = eps}.
    \item \textbf{Calcolo Errori:} Eseguendo calcoli come $a=123.1256$ e $A=123.12555551$, MatLab permette di quantificare esattamente $\Delta a$ ($\approx 4.45 \cdot 10^{-5}$) e $\delta a$ ($\approx 3.61 \cdot 10^{-7}$), confermando la teoria sulle cifre corrette (4 decimali, 7 significative).
\end{itemize}

\subsection{Opzioni Macchina e Cancellazione Numerica}

\paragraph{Operazioni Macchina ed Errori}
Una conseguenza diretta della rappresentazione finita dei numeri è l'impossibilità di implementare esattamente le operazioni aritmetiche. Il risultato di un'operazione tra due numeri macchina potrebbe non essere un numero macchina (causando overflow, underflow o necessitando di più cifre per la mantissa).
Si definiscono quindi le \textit{operazioni macchina} ($\oplus, \ominus, \otimes, \oslash$), dove il risultato è l'arrotondamento del risultato esatto dell'operazione aritmetica.
Per ogni operazione $\circ \in \{+, -, \times, /\}$ vale la relazione fondamentale:
$$ fl(A \circ B) = (A \circ B)(1 + \delta) \quad \text{con} \quad |\delta| \le u \le \epsilon $$
dove $u$ è l'unità di roundoff e $\epsilon$ l'epsilon macchina.
Questo significa che ogni singola operazione introduce un errore relativo limitato dalla precisione di macchina. Lo standard IEEE 754 utilizza \textit{bit di guardia} (registri estesi temporanei) per minimizzare questo errore, garantendo che anche per la radice quadrata valga $fl(\sqrt{A}) = \sqrt{A}(1+\delta)$.

\paragraph{Proprietà delle Operazioni Macchina}
A differenza dell'aritmetica reale, nell'aritmetica di macchina:
\begin{itemize}
    \item La \textit{proprietà commutativa} vale ($A \oplus B = B \oplus A$).
    \item La \textit{proprietà associativa} NON vale: $(A \oplus B) \oplus C \neq A \oplus (B \oplus C)$.
    \item La \textit{proprietà distributiva} NON vale.
\end{itemize}
Un'anomalia significativa è la non unicità dell'elemento neutro della somma. Se $|B| \ll |A|$ (molto più piccolo), può accadere che:
$$ A \oplus B = A $$
Questo avviene perché, per sommare due numeri, il calcolatore deve allineare gli esponenti. Se la differenza di esponenti è tale da far scorrere la mantissa di $B$ fuori dai registri disponibili (oltre le 16 cifre in doppia precisione), $B$ viene trattato come 0 rispetto ad $A$.

\paragraph{Strategie di Somma (Ascendente vs Discendente)}
Dovendo sommare molti numeri positivi con ordini di grandezza diversi, l'ordine delle operazioni influenza drasticamente la precisione.
\begin{itemize}
    \item \textit{Ordine Discendente (dal più grande al più piccolo):} I numeri piccoli vengono sommati a una somma parziale già grande. A causa dell'allineamento degli esponenti, le cifre significative dei numeri piccoli vengono perse ("tagliate fuori").
    \item \textit{Ordine Ascendente (dal più piccolo al più grande):} Si sommano prima i numeri piccoli tra loro, accumulando un valore significativo prima di sommarlo ai numeri grandi.
\end{itemize}
\textit{Esempio numerico:} Sommando una serie di numeri da $0.8999 \cdot 10^4$ a $0.1580 \cdot 10^0$:
\begin{itemize}
    \item Somma discendente: 3 cifre significative corrette (errore relativo $\approx 10^{-3}$).
    \item Somma ascendente: 5 cifre significative corrette (errore relativo $\approx 10^{-4}$).
\end{itemize}

\paragraph{Cancellazione Numerica}
La \textit{cancellazione numerica} è un fenomeno critico che causa una grave perdita di cifre significative. Si verifica sottraendo due numeri "quasi uguali" ($x_1 \approx x_2$).
Se $x = x_1 - x_2$ è molto piccolo, l'errore relativo esplode:
$$ \delta x = \frac{|fl(x_1 - x_2) - x|}{|x|} \to \infty $$
Per evitare la cancellazione, si devono riformulare le espressioni analitiche.
\textit{Esempi di tecniche risolutive:}
\begin{itemize}
    \item \textit{Razionalizzazione:} $\sqrt{x+\delta} - \sqrt{x} \rightarrow \frac{\delta}{\sqrt{x+\delta} + \sqrt{x}}$
    \item \textit{Identità trigonometriche:} $\cos(x+\delta) - \cos(x) \rightarrow -2\sin(\frac{\delta}{2})\sin(x+\frac{\delta}{2})$
    \item \textit{Sviluppo di Taylor:} Per $|\delta| \ll |x|$, $f(x+\delta) - f(x) \approx f'(x)\delta$.
\end{itemize}

\paragraph{Caso Studio: Equazione di Secondo Grado}
Per l'equazione $ax^2+bx+c=0$, la formula classica $x_{1,2} = \frac{-b \pm \sqrt{b^2-4ac}}{2a}$ è instabile se $b^2 \gg 4ac$, poiché $\sqrt{b^2-4ac} \approx |b|$, portando alla cancellazione in una delle due radici.
\textit{Algoritmo stabile:}
1. Calcolare la radice che non comporta cancellazione (sommando termini dello stesso segno):
$$ x_1 = \frac{-b - \text{sign}(b)\sqrt{b^2-4ac}}{2a} $$
2. Calcolare la seconda radice usando la relazione di Viète:
$$ x_2 = \frac{c}{ax_1} $$
L'applicazione della formula classica può portare alla perdita di numerose cifre significative (es. da 16 a 13 cifre corrette).

\paragraph{Analisi Grafica della Cancellazione (Polinomi)}
Confrontando due espressioni analiticamente equivalenti:
1. $y_1 = (1-x)^6$
2. $y_2 = x^6 - 6x^5 + 15x^4 - 20x^3 + 15x^2 - 6x + 1$ (Espansione)
Valutandole in un intorno molto piccolo di $x=1$ (es. $[0.999, 1.001]$):
\begin{itemize}
    \item $y_1$ mantiene un andamento liscio e corretto.
    \item $y_2$ mostra oscillazioni violente e prive di senso fisico ("rumore").
\end{itemize}
Le oscillazioni in $y_2$ sono dovute al fatto che si stanno sommando e sottraendo termini molto grandi (come $20x^3$) per ottenere un risultato vicino allo zero. Le quantità coinvolte nell'espressione espansa hanno più cifre in comune rispetto alla forma compatta, massimizzando l'errore di cancellazione.

\paragraph{Verifiche in MatLab}
Alcuni esperimenti al calcolatore confermano la teoria:
\begin{itemize}
    \item \textit{Violazione Associatività:} Dati $a=0.8 \cdot 10^9$, $b=5.0009 \cdot 10^3$, $c=-5.0008 \cdot 10^3$, il calcolo $a \times (b+c)$ fornisce il risultato corretto, mentre $a \times b + a \times c$ (che esegue prodotti grandi prima della cancellazione) dà un risultato diverso e meno preciso.
    \item \textit{Limiti Funzionali:} Il calcolo di $y = \frac{1-\cos(t)}{t^2}$ per $t \to 0$ perde precisione rapidamente (fino a dare 0 invece di 0.5). La forma equivalente $y = \frac{1}{2} \left( \frac{\sin(t/2)}{t/2} \right)^2$ rimane stabile fino alla precisione di macchina.
\end{itemize}

\subsection{Propagazione degli Errori Introdotti nei Dati Iniziali}
\paragraph{Condizionamento di un Problema}
Il condizionamento è una misura di quanto i risultati di un problema matematico siano sensibili a piccoli cambiamenti nei dati iniziali.
\begin{itemize}
    \item Se a "piccoli" cambiamenti nei dati corrispondono "grandi" cambiamenti nei risultati, il problema si dice \textit{mal condizionato}.
    \item In caso contrario, si dice \textit{ben condizionato}.
\end{itemize}
La quantità che quantifica questa amplificazione dell'errore è detta \textit{indice di condizionamento} ($K$). È fondamentale notare che il condizionamento è una proprietà intrinseca del problema matematico e non dipende dall'algoritmo usato o dagli errori di arrotondamento della macchina.

\paragraph{Analisi del Condizionamento: Il caso della Somma}
Per determinare l'indice di condizionamento, analizziamo l'operazione di somma $z = x + y$.
Supponiamo di perturbare i dati iniziali con errori $\Delta x$ e $\Delta y$, ottenendo il risultato perturbato:
$$ \overline{z} = (x + \Delta x) + (y + \Delta y) $$
Calcoliamo l'errore relativo $\delta z$ propagato sul risultato:
$$ \delta z = \frac{|z - \overline{z}|}{|z|} = \frac{|(x+y) - (x+\Delta x + y + \Delta y)|}{|x+y|} = \frac{|\Delta x + \Delta y|}{|x+y|} $$
Applicando la disuguaglianza triangolare:
$$ \delta z \le \frac{|x| \frac{|\Delta x|}{|x|} + |y| \frac{|\Delta y|}{|y|}}{|x+y|} \le \frac{\max\{|x|, |y|\}}{|x+y|} \left( \frac{|\Delta x|}{|x|} + \frac{|\Delta y|}{|y|} \right) $$
Definendo $\delta x$ e $\delta y$ come gli errori relativi sui dati, otteniamo:
$$ \delta z \le K (\delta x + \delta y) \quad \text{con} \quad K = \frac{\max\{|x|, |y|\}}{|x+y|} $$
Il fattore $K$ rappresenta l'indice di condizionamento. Se $x$ e $y$ sono molto vicini in modulo ma di segno opposto ($x \approx -y$), il denominatore $|x+y|$ tende a 0, facendo esplodere $K$. Questo conferma che la somma algebrica di numeri quasi opposti è un problema mal condizionato (fenomeno della cancellazione numerica).

\paragraph{Definizione Generale}
Dato un problema $f(x)$, si cerca una relazione del tipo:
$$ \frac{|f(x) - f(\overline{x})|}{|f(x)|} \le K \frac{|\Delta x|}{|x|} $$
Più $K$ è piccolo, più il problema è ben condizionato.

\paragraph{Esempio di Problema Mal Condizionato (Sistema Lineare)}
Consideriamo il sistema:
$$ \begin{cases} x_1 - x_2 = 1 \\ x_1 - 1.00001x_2 = 0 \end{cases} $$
Soluzione esatta: $x_1 = 100001, x_2 = 100000$.
Perturbiamo il coefficiente di $x_2$ nella seconda equazione di una quantità minima ($0.2 \cdot 10^{-4}$), ottenendo $-0.99999$. Il nuovo sistema:
$$ \begin{cases} y_1 - y_2 = 1 \\ y_1 - 0.99999y_2 = 0 \end{cases} $$
fornisce la soluzione $y_1 = -99999, y_2 = -100000$.
Una perturbazione infinitesimale sui dati ha stravolto la soluzione: il problema è mal condizionato.

\paragraph{Stabilità di un Algoritmo}
La stabilità riguarda il metodo risolutivo, non il problema in sé. Un algoritmo è \textit{instabile} se amplifica gli errori di arrotondamento durante il calcolo della soluzione di un problema ben condizionato.

\paragraph{Esempio: Gauss vs Gauss con Pivoting}
Consideriamo il sistema (con $\alpha = 0.5 \cdot 10^{-11}$):
$$ \begin{cases} \alpha x_1 + x_2 = 1 + \alpha \\ x_1 = 1 \end{cases} $$
La soluzione esatta è $x_1 = 1, x_2 = 1$. Il problema è ben condizionato ($K \approx 1$).

\textit{1. Metodo di Eliminazione di Gauss (senza pivoting):}
Moltiplichiamo la prima riga per $-1/\alpha$ e sommiamo alla seconda. A causa della limitata precisione macchina e della divisione per un numero molto piccolo ($\alpha$), si verificano errori di arrotondamento massicci.
Il risultato calcolato è $x_1 \approx 1.00000008...$, $x_2 = 1$. L'algoritmo è instabile.

\textit{2. Metodo con Pivoting (scambio righe):}
Scambiamo le righe per avere il coefficiente maggiore come pivot:
$$ \begin{cases} x_1 = 1 \\ \alpha x_1 + x_2 = 1 + \alpha \end{cases} $$
Applicando l'eliminazione, si ottiene la soluzione esatta $x_1 = 1, x_2 = 1$. L'algoritmo è stabile.

\paragraph{Classificazione dei Risultati}
La precisione finale dipende dalla combinazione tra problema e algoritmo:
\begin{itemize}
    \item \textit{Problema mal condizionato + Qualsiasi algoritmo:} Risultati inaffidabili (amplificazione errori dati).
    \item \textit{Problema ben condizionato + Algoritmo instabile:} Risultati inaffidabili (propagazione errori calcolo).
    \item \textit{Problema ben condizionato + Algoritmo stabile:} Massima precisione raggiungibile.
\end{itemize}

\paragraph{Verifiche MatLab e Stima dell'Errore}
MatLab permette di calcolare l'indice di condizionamento con \texttt{cond(A, inf)}.
\begin{itemize}
    \item Nel primo sistema (mal condizionato), $K \approx 4 \cdot 10^5$.
    L'errore atteso è $\approx K \cdot \epsilon_{macchina} \approx 10^5 \cdot 10^{-16} = 10^{-11}$.
    I test numerici confermano che si ottengono solo 11 cifre significative corrette, perdendone circa 5 rispetto alla precisione doppia standard.
    \item Nel secondo sistema (ben condizionato), $K = 1$.
    L'errore atteso è dell'ordine di $\epsilon_{macchina}$ ($10^{-16}$). Usando l'operatore \texttt{\textbackslash} (che usa algoritmo stabile con pivoting), si ottengono 16 cifre significative corrette.
\end{itemize}

\paragraph{Esempio di Stabilità con Overflow}
Dati $a = 1.4 \cdot 10^{154}$ e $b = 1.3 \cdot 10^{154}$, calcoliamo $a^2 - b^2$.
\begin{itemize}
    \item Algoritmo 1: \texttt{a\textasciicircum 2 - b\textasciicircum 2}. Il calcolo intermedio $a^2$ supera il massimo rappresentabile ($10^{308}$), generando \texttt{Inf} (Overflow).
    \item Algoritmo 2: \texttt{(a-b)*(a+b)}. I fattori rimangono nel range rappresentabile. Il risultato è corretto ($\approx 2.7 \cdot 10^{307}$).
\end{itemize}
Questo dimostra come forme algebricamente equivalenti possano avere stabilità numerica diversa.

\vspace{20pt}
\section{Wolfram Mathematica}

\vspace{20pt}
\section{Risoluzione di un Sistema Lineare Quadrato}
\subsection{}
\subsection{}
\subsection{}
\subsection{}
\subsection{}

\vspace{20pt}
\section{Metodi Numerici per la Risoluzione di un Sistema Lineare Rettangolare nel Senso dei Minimi Quadrati}
\subsection{}
\subsection{}
\subsection{}
\subsection{}
\subsection{}

\vspace{20pt}
\section{Metodi Numerici per la Risoluzione di una Equazione non Lineare}
\subsection{}
\subsection{}
\subsection{}
\subsection{}
\subsection{}

\end{document}
